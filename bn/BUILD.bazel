# Copyright 2016, 2017 Google LLC. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

package(default_visibility = ["//visibility:public"])

sh_test(
    name = "zero_width_test",
    timeout = "short",
    srcs = ["//utils:eval.sh"],
    args = [
        """
        cd $$(dirname $(location zero_width.py))
        for py in python python2 python3; do
          if which $$py; then
            $$py -m unittest zero_width
          fi
        done
        """,
    ],
    data = ["zero_width.py"],
)

sh_test(
    name = "ipa_phonemes_are_uniquely_decodable",
    timeout = "short",
    srcs = ["//utils:eval.sh"],
    args = [
        """
        cut -f 2 $(location phonemes.txt) |
        $(location //utils:uniquely_decodable)
        """,
    ],
    data = [
        "phonemes.txt",
        "//utils:uniquely_decodable",
    ],
)

genrule(
    name = "preprocess_lexicon",
    srcs = ["//bn/data:lexicon.tsv"],
    outs = ["preprocessed_lexicon.tsv"],
    cmd = """
        paste <(
          grep '^[^#a-z]' $< |
          cut -f 1 |
          $(location //utils:thrax_g2p) \
            --far=$(location //mul_034:Beng.far) \
            --far_g2p_key=G2P_PREPROCESS \
            --output_labels=$(location //mul_034:grapheme.syms)
        ) <(
          grep '^[^#a-z]' $< |
          cut -f 2 |
          sed 's/ \\.//g'
        ) > $@
        """,
    tools = [
        "//mul_034:Beng.far",
        "//mul_034:grapheme.syms",
        "//utils:thrax_g2p",
    ],
)

sh_test(
    name = "lexicon_test",
    timeout = "moderate",
    srcs = ["//utils:eval.sh"],
    args = [
        """
        cut -f 2,3 $(location preprocessed_lexicon.tsv) |
        $(location //festus:lexicon-diagnostics) \
          --alignables=$(location alignables.txt) \
          --unique_alignments
        """,
    ],
    data = [
        "alignables.txt",
        "preprocessed_lexicon.tsv",
        "//festus:lexicon-diagnostics",
    ],
)
